{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Businesses: Cleaning and Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to inspect and wrangle the `business.json` file from the yelp dataset.\n",
    "At each feature extracting/cleaning step, the data is saved in a separate csv file in the format `business_feature.csv` such that we can trace back the file origin. This is also to avoid ending up with a massing dataframe with too many features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from collections import Counter, OrderedDict\n",
    "import calendar\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(r\"C:\\Thạc Sĩ\\New folder\\PredictBusinessSuccess\"))  # Thêm đường dẫn cha của thư mục wrangle\n",
    "import utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load + Assess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tnhfDv5Il8EaGSXZGiuQGg</td>\n",
       "      <td>Garaje</td>\n",
       "      <td>4753rdSt</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94107</td>\n",
       "      <td>37.781753</td>\n",
       "      <td>-122.396122</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1198</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsTakeOut': True, 'BusinessParking'...</td>\n",
       "      <td>[Mexican, Burgers, Gastropubs]</td>\n",
       "      <td>{'Monday': '10:00-21:00', 'Tuesday': '10:00-21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id    name   address           city state postal_code  \\\n",
       "0  tnhfDv5Il8EaGSXZGiuQGg  Garaje  4753rdSt  San Francisco    CA       94107   \n",
       "\n",
       "    latitude   longitude  stars  review_count  is_open  \\\n",
       "0  37.781753 -122.396122    4.5          1198        1   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  {'RestaurantsTakeOut': True, 'BusinessParking'...   \n",
       "\n",
       "                       categories  \\\n",
       "0  [Mexican, Burgers, Gastropubs]   \n",
       "\n",
       "                                               hours  \n",
       "0  {'Monday': '10:00-21:00', 'Tuesday': '10:00-21...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('../data/business.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df_bus = pd.DataFrame([data])\n",
    "#download data\n",
    "#df_bus = utils.chunk_loader(business_dir, read_limit=-1)\n",
    "#df_bus = pd.read_json(business_dir, orient='columns',lines=True)\n",
    "#df_bus = pd.read_json(business_dir)  # KHÔNG dùng lines=True\n",
    "df_bus.head()\n",
    "\n",
    "#head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape\n",
    "df_bus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id      object\n",
       "name             object\n",
       "address          object\n",
       "city             object\n",
       "state            object\n",
       "postal_code      object\n",
       "latitude        float64\n",
       "longitude       float64\n",
       "stars           float64\n",
       "review_count      int64\n",
       "is_open           int64\n",
       "attributes       object\n",
       "categories       object\n",
       "hours            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data types\n",
    "df_bus.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.781753</td>\n",
       "      <td>-122.396122</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>37.781753</td>\n",
       "      <td>-122.396122</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37.781753</td>\n",
       "      <td>-122.396122</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.781753</td>\n",
       "      <td>-122.396122</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.781753</td>\n",
       "      <td>-122.396122</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>37.781753</td>\n",
       "      <td>-122.396122</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        latitude   longitude  stars  review_count  is_open\n",
       "count   1.000000    1.000000    1.0           1.0      1.0\n",
       "mean   37.781753 -122.396122    4.5        1198.0      1.0\n",
       "std          NaN         NaN    NaN           NaN      NaN\n",
       "min    37.781753 -122.396122    4.5        1198.0      1.0\n",
       "25%    37.781753 -122.396122    4.5        1198.0      1.0\n",
       "50%    37.781753 -122.396122    4.5        1198.0      1.0\n",
       "75%    37.781753 -122.396122    4.5        1198.0      1.0\n",
       "max    37.781753 -122.396122    4.5        1198.0      1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick stats\n",
    "df_bus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id     0.0\n",
       "name            0.0\n",
       "address         0.0\n",
       "city            0.0\n",
       "state           0.0\n",
       "postal_code     0.0\n",
       "latitude        0.0\n",
       "longitude       0.0\n",
       "stars           0.0\n",
       "review_count    0.0\n",
       "is_open         0.0\n",
       "attributes      0.0\n",
       "categories      0.0\n",
       "hours           0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percent missing\n",
    "df_bus.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning to-do list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the business dataframe above, there are several features that need to be cleaned.\n",
    "The list below offers a roadmap to addressing these issues although it might not be comprehensive. During the process we might need to add additional steps.\n",
    "We understand that some data types are nested within the columns, and that these data types might not be stored  in the appropirate manner.\n",
    "\n",
    "\n",
    "- address\n",
    "    - make everything lower case\n",
    "    - extract feature: if on road/boulevard/ave/etc...\n",
    "- attributes\n",
    "    - break up dict to dummy variables\n",
    "- business_id\n",
    "    - no changes\n",
    "- categories\n",
    "    - make everything lower?\n",
    "    - dummy variables and split by comma character\n",
    "    - note that not everything is a restaurant (plumbers)\n",
    "- city\n",
    "    - maybe lower case?\n",
    "- hours\n",
    "    - split dict by days\n",
    "        - open hour monday\n",
    "        - close hour monday\n",
    "        - etc...\n",
    "    - figure out placeholder value for None\n",
    "    - check if correlation between closed restaurant and no hours posted\n",
    "- is_open\n",
    "    - no changes\n",
    "    - 82% are open, 18% are dead businesses\n",
    "- latitude\n",
    "    - no changes\n",
    "- longitude\n",
    "    - no changes\n",
    "- name\n",
    "    - no changes\n",
    "- postal_code\n",
    "    - replace zip code with integer representation\n",
    "- review_count\n",
    "    - note that lowest value is 3\n",
    "- stars\n",
    "    - no changes\n",
    "- state\n",
    "    - some are canadian\n",
    "    - add feature: is in USA yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping dict for replacing and fixing data types\n",
    "bool_to_int = {True: 1, False: 0, np.nan: 0, 'True': 1, 'False': 0, 'None': 0, None: 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create deep copy\n",
    "df_bus_adr = df_bus.copy()\n",
    "#make everything lower case\n",
    "df_bus_adr['address'] = df_bus_adr['address'].str.lower()\n",
    "#remove punctuation\n",
    "df_bus_adr['address'] = df_bus_adr['address'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define counter object\n",
    "adr_counter = Counter()\n",
    "#loop over every address entry\n",
    "for add in df_bus_adr.address:\n",
    "    #loop over each individial word\n",
    "    for word in add.lower().split():\n",
    "        #add word to counter\n",
    "        adr_counter[word] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4753rdst', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list top k words\n",
    "adr_counter.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#road type mapping to homogenize road names\n",
    "road_type_dict = {'rd': 'road','rue': 'road', 'avenue': 'ave',\n",
    "                  'street': 'str', 'blvd': 'boulevard',\n",
    "                  'drive': 'dr', 'highway': 'hwy',\n",
    "                  'parkway': 'pkwy', 'center': 'ct', 'lane': 'ln'}\n",
    "\n",
    "#replace names\n",
    "df_bus_adr['address'] = df_bus_adr['address'].replace(road_type_dict, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dr', 'pkwy', 'ln', 'ct', 'ave', 'road', 'str', 'boulevard', 'hwy']\n"
     ]
    }
   ],
   "source": [
    "#get list of finalized road values\n",
    "#set to remove duplicates\n",
    "road_types_list = list(set(road_type_dict.values()))\n",
    "print(road_types_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15488\\594145455.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  road_type_df = pd.DataFrame.from_dict(road_col_dict).replace({False:0, True:1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr</th>\n",
       "      <th>pkwy</th>\n",
       "      <th>ln</th>\n",
       "      <th>ct</th>\n",
       "      <th>ave</th>\n",
       "      <th>road</th>\n",
       "      <th>str</th>\n",
       "      <th>boulevard</th>\n",
       "      <th>hwy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dr  pkwy  ln  ct  ave  road  str  boulevard  hwy\n",
       "0   0     0   0   0    0     1    0          0    0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dict for dummies\n",
    "road_col_dict = {}\n",
    "#iterate over road types\n",
    "for road in road_types_list:\n",
    "    #create a dummy for that type\n",
    "    dum_col = df_bus_adr['address'].str.contains(road)\n",
    "    #add it to the dict\n",
    "    road_col_dict[road] = dum_col\n",
    "\n",
    "#convert boolean to 1/0\n",
    "road_type_df = pd.DataFrame.from_dict(road_col_dict).replace({False:0, True:1})\n",
    "\n",
    "road_type_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key for reference in case we want to join tables\n",
    "road_type_df['business_id'] = df_bus['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# tạo thư mục nếu chưa có\n",
    "os.makedirs('data/cleaned', exist_ok=True)\n",
    "\n",
    "# lưu file\n",
    "road_type_df.to_csv('data/cleaned/business_roadtype.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatively we can create a categorical series instead of one hot encoding to reduce the dimensionality of the combined dataframe. We can do this because the categories are mutually exclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop index col since we use dataframe later down\n",
    "road_type_df = road_type_df.drop(columns=['business_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15488\\309533305.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  road_type_df_cats = road_type_df_cats.replace(road_to_cat_dict)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15488\\309533305.py:11: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  road_type_df_cats = road_type_df_cats.replace(road_to_cat_dict)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "dtype: category\n",
       "Categories (1, int64): [6]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dict mapping for road types\n",
    "road_to_cat_dict = dict(zip(road_type_df.columns, np.arange(1, len(road_type_df.columns)+1)))\n",
    "\n",
    "#stak dataframe\n",
    "road_type_df_stack = road_type_df.stack()\n",
    "\n",
    "#convert to series\n",
    "road_type_df_cats = pd.Series(pd.Categorical(road_type_df_stack[road_type_df_stack!=0].index.get_level_values(1)))\n",
    "\n",
    "#replace with dict\n",
    "road_type_df_cats = road_type_df_cats.replace(road_to_cat_dict)\n",
    "\n",
    "\n",
    "road_type_df_cats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road_type_df_cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15488\\1393366029.py:4: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_bus['road_type'] = df_bus['road_type'].astype('object').fillna(0)\n"
     ]
    }
   ],
   "source": [
    "df_bus['road_type'] = road_type_df_cats\n",
    "\n",
    "#fill missing values with 0\n",
    "df_bus['road_type'] = df_bus['road_type'].astype('object').fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can't necessarily rank the importance of the address based on its designation. A road might be more visited than a parkway, and the numbering of the road might not indicate anything. Thinking ahead, we believe that using one hot encoding might be the best solution for this categorical variable\n",
    "\n",
    "### Replace postal codes with corresponding integer code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatively:\n",
    "use IRS data to get income by zip code\n",
    "\n",
    "https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-2016-zip-code-data-soi\n",
    "\n",
    "https://www.irs.gov/statistics/soi-tax-stats-individual-income-tax-statistics-zip-code-data-soi\n",
    "\n",
    "\n",
    "For Canada:\n",
    "https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/hlt-fst/inc-rev/Table.cfm?Lang=Eng&T=102&PR=0&D1=1&RPP=25&SR=1&S=108&O=D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15488\\1211755027.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_bus['postal_code'] = df_bus['postal_code'].replace(postal_to_int)\n"
     ]
    }
   ],
   "source": [
    "#get unique postal codes\n",
    "unique_postal = df_bus['postal_code'].unique().tolist()\n",
    "\n",
    "#map code to integer representation\n",
    "postal_to_int = dict(zip(unique_postal, np.arange(0, len(unique_postal))))\n",
    "\n",
    "#reverse mapping for reference\n",
    "int_to_postal = {v:k for k,v in postal_to_int.items()}\n",
    "\n",
    "#replace in dataframe\n",
    "df_bus['postal_code'] = df_bus['postal_code'].replace(postal_to_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RestaurantsTakeOut</th>\n",
       "      <th>BusinessParking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>{'garage': False, 'street': True, 'validated':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RestaurantsTakeOut                                    BusinessParking\n",
       "0                True  {'garage': False, 'street': True, 'validated':..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#break up dict inside df\n",
    "df_atr = df_bus['attributes'].apply(pd.Series)\n",
    "df_atr.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RestaurantsTakeOut      bool\n",
       "BusinessParking       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect types\n",
    "df_atr.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BusinessParking'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#select cols that are still as objects\n",
    "df_atr_obj_cols = df_atr.select_dtypes(include='object').columns\n",
    "print(df_atr_obj_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BusinessParking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'garage': False, 'street': True, 'validated':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     BusinessParking\n",
       "0  {'garage': False, 'street': True, 'validated':..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_atr[df_atr_obj_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_dict_to_df(series):\n",
    "    \"\"\"\n",
    "    Takes in a pandas series with dicts stored as strings\n",
    "    returns dataframe with dict keys as columns\n",
    "    \n",
    "    serires: pandas series\n",
    "    \"\"\"\n",
    "    eval_list = []\n",
    "    for sr in series:\n",
    "        if not pd.isna(sr):\n",
    "            eval_list.append(eval(sr))\n",
    "        else:\n",
    "            eval_list.append(np.nan)\n",
    "    \n",
    "    eval_df = pd.Series(eval_list).apply(pd.Series)  \n",
    "    \n",
    "    #drop cols that are all nan\n",
    "    eval_df = eval_df.dropna(axis=1, how='all')\n",
    "    \n",
    "    \n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#store col names\n",
    "dict_cols_list = []\n",
    "\n",
    "for col in df_atr_obj_cols:\n",
    "    #if contains a curly bracket, then assume column is a dict as string\n",
    "    if df_atr[col].str.contains('{').any():\n",
    "        dict_cols_list.append(col)\n",
    "print(dict_cols_list)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     dict_col_df_list\u001b[38;5;241m.\u001b[39mappend(temp_df)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#combine all in one column\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m dict_col_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_col_df_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m dict_col_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[1;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[0;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[1;34m(self, objs, keys)\u001b[0m\n\u001b[0;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "#store dataframes from dict nested columns\n",
    "dict_col_df_list = []\n",
    "\n",
    "for col in dict_cols_list:\n",
    "    #apply string to dict evaluation\n",
    "    temp_df = str_dict_to_df(df_atr[col])\n",
    "    #append to list\n",
    "    dict_col_df_list.append(temp_df)\n",
    "\n",
    "#combine all in one column\n",
    "dict_col_df = pd.concat(dict_col_df_list, axis=1)\n",
    "dict_col_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NoiseLevel', 'WiFi', 'Alcohol', 'RestaurantsAttire', 'BYOBCorkage', 'Smoking', 'AgesAllowed']\n"
     ]
    }
   ],
   "source": [
    "#store dummy attribute columns in list\n",
    "atr_dum_df_cols = []\n",
    "\n",
    "#iterate over object columns\n",
    "for col in df_atr_obj_cols:\n",
    "    #if contains a categorical variable then it begins with a u\n",
    "    if df_atr[col].str.contains(\"u'\").any():\n",
    "        #add to the list\n",
    "        atr_dum_df_cols.append(col)\n",
    "\n",
    "#print out list\n",
    "print(atr_dum_df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoiseLevel\n",
      "[nan \"u'loud'\" \"u'average'\" \"'average'\" \"u'quiet'\" \"'loud'\" \"'very_loud'\"\n",
      " \"'quiet'\" \"u'very_loud'\" 'None']\n",
      "--------------------------------------------------\n",
      "WiFi\n",
      "[nan \"u'no'\" \"'free'\" \"u'free'\" \"'no'\" \"u'paid'\" \"'paid'\" 'None']\n",
      "--------------------------------------------------\n",
      "Alcohol\n",
      "[nan \"u'full_bar'\" \"u'beer_and_wine'\" \"u'none'\" \"'beer_and_wine'\" \"'none'\"\n",
      " \"'full_bar'\" 'None']\n",
      "--------------------------------------------------\n",
      "RestaurantsAttire\n",
      "[nan \"u'casual'\" \"'casual'\" \"'dressy'\" \"u'dressy'\" \"u'formal'\" 'None'\n",
      " \"'formal'\"]\n",
      "--------------------------------------------------\n",
      "BYOBCorkage\n",
      "[nan \"'no'\" \"'yes_corkage'\" \"'yes_free'\" \"u'no'\" \"u'yes_free'\"\n",
      " \"u'yes_corkage'\" 'None']\n",
      "--------------------------------------------------\n",
      "Smoking\n",
      "[nan \"u'no'\" \"u'outdoor'\" \"u'yes'\" \"'no'\" 'None' \"'outdoor'\" \"'yes'\"]\n",
      "--------------------------------------------------\n",
      "AgesAllowed\n",
      "[nan \"u'allages'\" \"u'21plus'\" \"u'18plus'\" \"u'19plus'\" 'None']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#explore unique entries in attribute columns\n",
    "for col in atr_dum_df_cols:\n",
    "    print(col)\n",
    "    print(df_atr[col].unique())\n",
    "    print(50*'-')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We build a dictionary to replace each categorical variable with a numerical value that corresponds to a sliding scale. For example we can rank attire from casual, to dressy, and to formal. This will reduce the feature space, and probably provide more information gain than a one hot encoding. For simplicity we will assume that a NaN is always the lowest value on the scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan: 0, \"u'loud'\": 3, \"u'average'\": 2, \"'average'\": 2, \"u'quiet'\": 1, \"'loud'\": 3, \"'very_loud'\": 4, \"'quiet'\": 1, \"u'very_loud'\": 4, 'None': 0}\n"
     ]
    }
   ],
   "source": [
    "#noise level\n",
    "noise_level_dict = dict(zip([np.nan, \"u'loud'\" ,\"u'average'\" ,\n",
    "                             \"'average'\" ,\"u'quiet'\" ,\"'loud'\" ,\n",
    "                             \"'very_loud'\", \"'quiet'\" ,\"u'very_loud'\" ,'None'], \n",
    "                            [0, 3, 2, \n",
    "                             2, 1, 3, \n",
    "                             4, 1 , 4, 0]))\n",
    "print(noise_level_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan: 0, \"u'no'\": 1, \"'free'\": 3, \"u'free'\": 3, \"'no'\": 1, \"u'paid'\": 2, \"'paid'\": 2, 'None': 0}\n"
     ]
    }
   ],
   "source": [
    "#free wifi is the best kind of wifi\n",
    "wifi_dict = dict(zip(\n",
    "    [np.nan ,\"u'no'\" ,\"'free'\" ,\n",
    "     \"u'free'\" ,\"'no'\" ,\"u'paid'\" ,\"'paid'\" ,'None'], \n",
    "    [0, 1, 3, \n",
    "     3, 1, 2, 2, 0]))\n",
    "print(wifi_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan: 0, \"u'full_bar'\": 2, \"u'beer_and_wine'\": 1, \"u'none'\": 0, \"'beer_and_wine'\": 1, \"'none'\": 0, \"'full_bar'\": 2, 'None': 0}\n"
     ]
    }
   ],
   "source": [
    "#more alcohol is better\n",
    "alcohol_dict = dict(zip([np.nan ,\"u'full_bar'\" ,\"u'beer_and_wine'\" ,\n",
    "                         \"u'none'\" ,\"'beer_and_wine'\" ,\"'none'\", \n",
    "                         \"'full_bar'\" ,'None'],\n",
    "                        [0, 2, 1, \n",
    "                         0, 1, 0, \n",
    "                         2, 0]))\n",
    "print(alcohol_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan: 0, \"u'casual'\": 1, \"'casual'\": 1, \"'dressy'\": 2, \"u'dressy'\": 2, \"u'formal'\": 3, 'None': 0, \"'formal'\": 3}\n"
     ]
    }
   ],
   "source": [
    "#rank by formality\n",
    "restaurant_attire_dict = dict(zip(\n",
    "    [np.nan ,\"u'casual'\" ,\"'casual'\" ,\n",
    "     \"'dressy'\" ,\"u'dressy'\" ,\"u'formal'\" ,\n",
    "     'None',\"'formal'\"], \n",
    "    [0, 1, 1, \n",
    "     2, 2, 3, \n",
    "     0, 3]))\n",
    "print(restaurant_attire_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan: 0, \"'no'\": 1, \"'yes_corkage'\": 2, \"'yes_free'\": 3, \"u'no'\": 1, \"u'yes_free'\": 3, \"u'yes_corkage'\": 2}\n"
     ]
    }
   ],
   "source": [
    "#free corkage is best\n",
    "byob_corkage_dict = dict(zip(\n",
    "    [np.nan ,\"'no'\" ,\"'yes_corkage'\" ,\n",
    "     \"'yes_free'\" ,\"u'no'\" ,\"u'yes_free'\",\"u'yes_corkage'\"],\n",
    "    [0, 1, 2, \n",
    "     3, 1, 3, 2]))\n",
    "print(byob_corkage_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan: 0, \"u'no'\": 1, \"u'outdoor'\": 2, \"u'yes'\": 3, \"'no'\": 1, 'None': 0, \"'outdoor'\": 2, \"'yes'\": 3}\n"
     ]
    }
   ],
   "source": [
    "#from least to most accomodating for smokers\n",
    "smoking_dict = dict(zip(\n",
    "    [np.nan ,\"u'no'\" ,\"u'outdoor'\" ,\n",
    "     \"u'yes'\" ,\"'no'\" ,'None' ,\n",
    "     \"'outdoor'\" ,\"'yes'\"], \n",
    "    [0, 1, 2, \n",
    "     3, 1, 0, \n",
    "     2, 3]))\n",
    "print(smoking_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan: 0, \"u'allages'\": 1, \"u'21plus'\": 4, \"u'18plus'\": 2, \"u'19plus'\": 3, 'None': 0}\n"
     ]
    }
   ],
   "source": [
    "#from youngest to oldest crowd\n",
    "ages_allowed_dict = dict(zip(\n",
    "    [np.nan ,\"u'allages'\" ,\"u'21plus'\" ,\n",
    "     \"u'18plus'\" ,\"u'19plus'\" ,'None'], \n",
    "    [0, 1, 4, \n",
    "     2, 3, 0]))\n",
    "print(ages_allowed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define mapping for replace method\n",
    "atr_dict_map = {'NoiseLevel': noise_level_dict, \n",
    "                'WiFi': wifi_dict, \n",
    "                'Alcohol': alcohol_dict, \n",
    "                'RestaurantsAttire': restaurant_attire_dict, \n",
    "                'BYOBCorkage': byob_corkage_dict, \n",
    "                'Smoking': smoking_dict, \n",
    "                'AgesAllowed': ages_allowed_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoiseLevel</th>\n",
       "      <th>WiFi</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>RestaurantsAttire</th>\n",
       "      <th>BYOBCorkage</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AgesAllowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NoiseLevel  WiFi  Alcohol  RestaurantsAttire BYOBCorkage  Smoking  \\\n",
       "0           0     0        0                  0           0        0   \n",
       "1           3     1        2                  1           0        0   \n",
       "2           2     1        1                  1           0        0   \n",
       "3           0     0        0                  0           0        0   \n",
       "4           0     0        0                  0           0        0   \n",
       "\n",
       "   AgesAllowed  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get a copy with relevant columns\n",
    "df_atr_categorical = df_atr[atr_dum_df_cols].copy()\n",
    "#apply replacement\n",
    "df_atr_categorical = df_atr_categorical.replace(atr_dict_map)\n",
    "\n",
    "df_atr_categorical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cell block below will return a one hot encoding of the categorical attributes above, uncomment if objective changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #store dummy dataframes in list\n",
    "# atr_dum_df_list = []\n",
    "\n",
    "# for col in atr_dum_df_cols:\n",
    "    \n",
    "#     #we do not want to modify the dataframe in place so create a copy\n",
    "#     temp_series = df_atr[col].copy()\n",
    "    \n",
    "    \n",
    "#     #fx messy inputs and remove u\n",
    "#     temp_series = temp_series.str.replace(\"u'\", \"\")\n",
    "#     #remove '\n",
    "#     temp_series= temp_series.str.replace(\"'\", \"\")\n",
    "        \n",
    "    \n",
    "#     #create dummies\n",
    "#     dum_df = pd.get_dummies(temp_series)\n",
    "#     #drop the None column\n",
    "#     dum_df = dum_df.drop(columns=['None'])\n",
    "        \n",
    "#     #fx messy col names in case we missed them\n",
    "#     dum_df.columns = dum_df.columns.str.replace(\"u'\", \"\")\n",
    "#     dum_df.columns = dum_df.columns.str.replace(\"'\", \"\")\n",
    "        \n",
    "#     #add prefixt\n",
    "#     dum_df = dum_df.add_prefix(col+'_')\n",
    "                \n",
    "#     #append to list\n",
    "#     atr_dum_df_list.append(dum_df)\n",
    "\n",
    "# #concat\n",
    "# atr_dum_df = pd.concat(atr_dum_df_list, axis=1)\n",
    "\n",
    "# atr_dum_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #standard preprocessing for restaurant price range since it has no u\n",
    "# atr_price_range = pd.get_dummies(df_atr['RestaurantsPriceRange2'])\n",
    "# atr_price_range = atr_price_range.drop(columns= ['None'])\n",
    "# atr_price_range = atr_price_range.add_prefix('price_range'+'_')\n",
    "\n",
    "# atr_price_range.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GoodForMeal', 'BusinessParking', 'Ambience', 'Music', 'BestNights', 'HairSpecializesIn', 'DietaryRestrictions', 'NoiseLevel', 'WiFi', 'Alcohol', 'RestaurantsAttire', 'BYOBCorkage', 'Smoking', 'AgesAllowed']\n"
     ]
    }
   ],
   "source": [
    "#add to the list\n",
    "atr_to_drop =  dict_cols_list + list(df_atr_categorical.columns)\n",
    "print(atr_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GoodForKids</th>\n",
       "      <th>RestaurantsReservations</th>\n",
       "      <th>Caters</th>\n",
       "      <th>RestaurantsTableService</th>\n",
       "      <th>RestaurantsTakeOut</th>\n",
       "      <th>RestaurantsPriceRange2</th>\n",
       "      <th>OutdoorSeating</th>\n",
       "      <th>BikeParking</th>\n",
       "      <th>HasTV</th>\n",
       "      <th>RestaurantsGoodForGroups</th>\n",
       "      <th>...</th>\n",
       "      <th>halal</th>\n",
       "      <th>soy_free</th>\n",
       "      <th>vegetarian</th>\n",
       "      <th>NoiseLevel</th>\n",
       "      <th>WiFi</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>RestaurantsAttire</th>\n",
       "      <th>BYOBCorkage</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AgesAllowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GoodForKids  RestaurantsReservations  Caters  RestaurantsTableService  \\\n",
       "0            0                        0       0                        0   \n",
       "1            1                        1       1                        1   \n",
       "2            1                        1       0                        1   \n",
       "3            0                        0       0                        0   \n",
       "4            0                        0       0                        0   \n",
       "\n",
       "   RestaurantsTakeOut RestaurantsPriceRange2  OutdoorSeating  BikeParking  \\\n",
       "0                   0                      0               0            0   \n",
       "1                   1                      2               0            0   \n",
       "2                   1                      2               0            1   \n",
       "3                   0                      0               0            0   \n",
       "4                   0                      0               0            0   \n",
       "\n",
       "   HasTV  RestaurantsGoodForGroups     ...       halal  soy_free  vegetarian  \\\n",
       "0      0                         0     ...           0         0           0   \n",
       "1      0                         1     ...           0         0           0   \n",
       "2      1                         1     ...           0         0           0   \n",
       "3      0                         0     ...           0         0           0   \n",
       "4      0                         0     ...           0         0           0   \n",
       "\n",
       "   NoiseLevel  WiFi  Alcohol  RestaurantsAttire  BYOBCorkage  Smoking  \\\n",
       "0           0     0        0                  0            0        0   \n",
       "1           3     1        2                  1            0        0   \n",
       "2           2     1        1                  1            0        0   \n",
       "3           0     0        0                  0            0        0   \n",
       "4           0     0        0                  0            0        0   \n",
       "\n",
       "   AgesAllowed  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine features in one dataframes\n",
    "df_atr_conc = pd.concat([df_atr.drop(columns=atr_to_drop),dict_col_df, df_atr_categorical], axis=1)\n",
    "\n",
    "#standardize name\n",
    "df_atr_conc.columns = df_atr_conc.columns.str.replace(\"-\", \"_\")\n",
    "\n",
    "#make 1/0\n",
    "df_atr_conc = df_atr_conc.replace(bool_to_int)\n",
    "\n",
    "df_atr_conc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GoodForKids', 'RestaurantsReservations', 'Caters',\n",
       "       'RestaurantsTableService', 'RestaurantsTakeOut',\n",
       "       'RestaurantsPriceRange2', 'OutdoorSeating', 'BikeParking', 'HasTV',\n",
       "       'RestaurantsGoodForGroups', 'RestaurantsDelivery',\n",
       "       'BusinessAcceptsCreditCards', 'BusinessAcceptsBitcoin',\n",
       "       'ByAppointmentOnly', 'AcceptsInsurance', 'GoodForDancing', 'CoatCheck',\n",
       "       'HappyHour', 'WheelchairAccessible', 'DogsAllowed', 'DriveThru',\n",
       "       'Corkage', 'BYOB', 'Open24Hours', 'RestaurantsCounterService',\n",
       "       'dessert', 'latenight', 'lunch', 'dinner', 'brunch', 'breakfast',\n",
       "       'garage', 'street', 'validated', 'lot', 'valet', 'romantic', 'intimate',\n",
       "       'classy', 'hipster', 'divey', 'touristy', 'trendy', 'upscale', 'casual',\n",
       "       'dj', 'background_music', 'no_music', 'jukebox', 'live', 'video',\n",
       "       'karaoke', 'monday', 'tuesday', 'friday', 'wednesday', 'thursday',\n",
       "       'sunday', 'saturday', 'straightperms', 'coloring', 'extensions',\n",
       "       'africanamerican', 'curly', 'kids', 'perms', 'asian', 'dairy_free',\n",
       "       'gluten_free', 'vegan', 'kosher', 'halal', 'soy_free', 'vegetarian',\n",
       "       'NoiseLevel', 'WiFi', 'Alcohol', 'RestaurantsAttire', 'BYOBCorkage',\n",
       "       'Smoking', 'AgesAllowed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick check for column names\n",
    "df_atr_conc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key for reference\n",
    "df_atr_conc['business_id'] = df_bus['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the work\n",
    "df_atr_conc.to_csv(path_or_buf='data/cleaned/business_attributes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter for original categories\n",
    "cat_counter = Counter()\n",
    "#loop through split categories\n",
    "for cat_split in df_bus['categories'].str.split(',| '):\n",
    "    #if statement to avoid none type is not iterable\n",
    "    if cat_split:\n",
    "        for cat in cat_split:\n",
    "            cat_counter[cat] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 596232),\n",
       " ('&', 129038),\n",
       " ('Services', 72809),\n",
       " ('Restaurants', 59382),\n",
       " ('Food', 47591),\n",
       " ('Shopping', 32643),\n",
       " ('Home', 31600),\n",
       " ('Spas', 23387),\n",
       " ('Bars', 21592),\n",
       " ('Beauty', 21518),\n",
       " ('Medical', 20510),\n",
       " ('Health', 18736),\n",
       " ('Hair', 15561),\n",
       " ('Local', 15405),\n",
       " ('Event', 14518),\n",
       " ('Repair', 13276),\n",
       " ('Automotive', 13203),\n",
       " ('Nightlife', 13095),\n",
       " ('Stores', 12969),\n",
       " ('Salons', 12847),\n",
       " ('Planning', 12740),\n",
       " ('American', 12580),\n",
       " ('Auto', 11392),\n",
       " ('Life', 10049),\n",
       " ('Arts', 9744)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see top k types\n",
    "cat_counter.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '&', 'Services', 'Restaurants', 'Food', 'Shopping', 'Home', 'Spas', 'Bars', 'Beauty', 'Medical', 'Health', 'Hair', 'Local', 'Event', 'Repair', 'Automotive', 'Nightlife', 'Stores', 'Salons', 'Planning', 'American', 'Auto', 'Life', 'Arts']\n",
      "\n",
      "selecting only top 10 relevant sections\n",
      "\n",
      "['Restaurants', 'Food', 'Shopping', 'Home', 'Spas', 'Bars', 'Beauty', 'Medical', 'Health', 'Hair']\n"
     ]
    }
   ],
   "source": [
    "#get keys for top k common categories\n",
    "top_cats = list(dict(cat_counter.most_common(25)).keys())\n",
    "print(top_cats)\n",
    "#note that the first 2 were space and & so skip those\n",
    "print(\"\\nselecting only top 10 relevant sections\\n\")\n",
    "top_cats = top_cats[3:13]\n",
    "print(top_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurants</th>\n",
       "      <th>Food</th>\n",
       "      <th>Shopping</th>\n",
       "      <th>Home</th>\n",
       "      <th>Spas</th>\n",
       "      <th>Bars</th>\n",
       "      <th>Beauty</th>\n",
       "      <th>Medical</th>\n",
       "      <th>Health</th>\n",
       "      <th>Hair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Restaurants  Food  Shopping  Home  Spas  Bars  Beauty  Medical  Health  \\\n",
       "0            0     0         0     0     0     0       0        0       0   \n",
       "1            1     1         0     0     0     0       0        0       0   \n",
       "2            1     0         0     0     0     1       0        0       0   \n",
       "3            0     0         0     0     0     0       0        0       0   \n",
       "4            0     0         1     1     0     0       0        0       0   \n",
       "\n",
       "   Hair  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dict for categories\n",
    "category_dict = {}\n",
    "for cat in top_cats:\n",
    "    #select relevant top 10 categories from before\n",
    "    dum_cat = df_bus['categories'].str.contains(cat)\n",
    "    #add it to the dict\n",
    "    category_dict[cat] = dum_cat\n",
    "    \n",
    "cat_type_df = pd.DataFrame.from_dict(category_dict).replace(bool_to_int)\n",
    "\n",
    "cat_type_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key for reference\n",
    "cat_type_df['business_id'] = df_bus['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the work\n",
    "cat_type_df.to_csv(path_or_buf='data/cleaned/business_cats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holy grail of date time format:\n",
    "\n",
    "http://strftime.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9:0-0:0</td>\n",
       "      <td>9:0-0:0</td>\n",
       "      <td>9:0-0:0</td>\n",
       "      <td>9:0-0:0</td>\n",
       "      <td>9:0-1:0</td>\n",
       "      <td>9:0-1:0</td>\n",
       "      <td>9:0-0:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17:30-21:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17:30-21:30</td>\n",
       "      <td>17:30-21:30</td>\n",
       "      <td>17:30-22:0</td>\n",
       "      <td>17:30-22:0</td>\n",
       "      <td>17:30-21:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8:0-17:0</td>\n",
       "      <td>8:0-17:0</td>\n",
       "      <td>8:0-17:0</td>\n",
       "      <td>8:0-17:0</td>\n",
       "      <td>8:0-17:0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7:0-23:0</td>\n",
       "      <td>7:0-23:0</td>\n",
       "      <td>7:0-23:0</td>\n",
       "      <td>7:0-23:0</td>\n",
       "      <td>7:0-23:0</td>\n",
       "      <td>7:0-23:0</td>\n",
       "      <td>7:0-23:0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Monday   Tuesday    Wednesday     Thursday      Friday    Saturday  \\\n",
       "0          NaN       NaN          NaN          NaN         NaN         NaN   \n",
       "1      9:0-0:0   9:0-0:0      9:0-0:0      9:0-0:0     9:0-1:0     9:0-1:0   \n",
       "2  17:30-21:30       NaN  17:30-21:30  17:30-21:30  17:30-22:0  17:30-22:0   \n",
       "3     8:0-17:0  8:0-17:0     8:0-17:0     8:0-17:0    8:0-17:0         NaN   \n",
       "4     7:0-23:0  7:0-23:0     7:0-23:0     7:0-23:0    7:0-23:0    7:0-23:0   \n",
       "\n",
       "       Sunday  \n",
       "0         NaN  \n",
       "1     9:0-0:0  \n",
       "2  17:30-21:0  \n",
       "3         NaN  \n",
       "4    7:0-23:0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split out the dict\n",
    "hours_day_df = df_bus['hours'].apply(pd.Series)\n",
    "hours_day_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_datetime(df, series):\n",
    "    \"\"\"\n",
    "    Takes in a pandas series with content stored as a string\n",
    "    must have format hour:minute - hour:minute\n",
    "    can have missing values\n",
    "    \n",
    "    df = pandas dataframe\n",
    "    series = pandas column name\n",
    "    \"\"\"\n",
    "    #create array for day of week\n",
    "    #weekday = list(calendar.day_abbr)\n",
    "    \n",
    "    #ordered dict container\n",
    "    serires_dict = OrderedDict()\n",
    "    \n",
    "    #hour container\n",
    "    open_hour = []\n",
    "    close_hour = []\n",
    "    \n",
    "    #split the series along the dash (-)\n",
    "    day = df[series].str.split(\"-\")\n",
    "\n",
    "    #iterate over days\n",
    "    for hour in day:\n",
    "        \n",
    "        #if not a nan the split will return a list\n",
    "        if type(hour)==list:\n",
    "            open_hour.append(hour[0])\n",
    "            close_hour.append(hour[1])\n",
    "        else:\n",
    "            #necessary nan for when not available\n",
    "            open_hour.append(np.nan)\n",
    "            close_hour.append(np.nan)\n",
    "            \n",
    "    #make a datetime object    \n",
    "    \n",
    "    open_hour_dt = pd.to_datetime(open_hour, dayfirst=True,format='%H:%M')\n",
    "    close_hour_dt = pd.to_datetime(close_hour, dayfirst=True, format='%H:%M')\n",
    "    \n",
    "    serires_dict[series+'_open'] = open_hour\n",
    "    serires_dict[series+'_close'] = close_hour\n",
    "    \n",
    "    hours_df = pd.DataFrame.from_dict(serires_dict)\n",
    "    \n",
    "    return hours_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Monday_open</th>\n",
       "      <th>Monday_close</th>\n",
       "      <th>Tuesday_open</th>\n",
       "      <th>Tuesday_close</th>\n",
       "      <th>Wednesday_open</th>\n",
       "      <th>Wednesday_close</th>\n",
       "      <th>Thursday_open</th>\n",
       "      <th>Thursday_close</th>\n",
       "      <th>Friday_open</th>\n",
       "      <th>Friday_close</th>\n",
       "      <th>Saturday_open</th>\n",
       "      <th>Saturday_close</th>\n",
       "      <th>Sunday_open</th>\n",
       "      <th>Sunday_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9:0</td>\n",
       "      <td>0:0</td>\n",
       "      <td>9:0</td>\n",
       "      <td>0:0</td>\n",
       "      <td>9:0</td>\n",
       "      <td>0:0</td>\n",
       "      <td>9:0</td>\n",
       "      <td>0:0</td>\n",
       "      <td>9:0</td>\n",
       "      <td>1:0</td>\n",
       "      <td>9:0</td>\n",
       "      <td>1:0</td>\n",
       "      <td>9:0</td>\n",
       "      <td>0:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17:30</td>\n",
       "      <td>21:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17:30</td>\n",
       "      <td>21:30</td>\n",
       "      <td>17:30</td>\n",
       "      <td>21:30</td>\n",
       "      <td>17:30</td>\n",
       "      <td>22:0</td>\n",
       "      <td>17:30</td>\n",
       "      <td>22:0</td>\n",
       "      <td>17:30</td>\n",
       "      <td>21:0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8:0</td>\n",
       "      <td>17:0</td>\n",
       "      <td>8:0</td>\n",
       "      <td>17:0</td>\n",
       "      <td>8:0</td>\n",
       "      <td>17:0</td>\n",
       "      <td>8:0</td>\n",
       "      <td>17:0</td>\n",
       "      <td>8:0</td>\n",
       "      <td>17:0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7:0</td>\n",
       "      <td>23:0</td>\n",
       "      <td>7:0</td>\n",
       "      <td>23:0</td>\n",
       "      <td>7:0</td>\n",
       "      <td>23:0</td>\n",
       "      <td>7:0</td>\n",
       "      <td>23:0</td>\n",
       "      <td>7:0</td>\n",
       "      <td>23:0</td>\n",
       "      <td>7:0</td>\n",
       "      <td>23:0</td>\n",
       "      <td>7:0</td>\n",
       "      <td>23:0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Monday_open Monday_close Tuesday_open Tuesday_close Wednesday_open  \\\n",
       "0         NaN          NaN          NaN           NaN            NaN   \n",
       "1         9:0          0:0          9:0           0:0            9:0   \n",
       "2       17:30        21:30          NaN           NaN          17:30   \n",
       "3         8:0         17:0          8:0          17:0            8:0   \n",
       "4         7:0         23:0          7:0          23:0            7:0   \n",
       "\n",
       "  Wednesday_close Thursday_open Thursday_close Friday_open Friday_close  \\\n",
       "0             NaN           NaN            NaN         NaN          NaN   \n",
       "1             0:0           9:0            0:0         9:0          1:0   \n",
       "2           21:30         17:30          21:30       17:30         22:0   \n",
       "3            17:0           8:0           17:0         8:0         17:0   \n",
       "4            23:0           7:0           23:0         7:0         23:0   \n",
       "\n",
       "  Saturday_open Saturday_close Sunday_open Sunday_close  \n",
       "0           NaN            NaN         NaN          NaN  \n",
       "1           9:0            1:0         9:0          0:0  \n",
       "2         17:30           22:0       17:30         21:0  \n",
       "3           NaN            NaN         NaN          NaN  \n",
       "4           7:0           23:0         7:0         23:0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hours_df_list = []\n",
    "\n",
    "for col in hours_day_df.columns:\n",
    "    temp_hour_df = series_to_datetime(hours_day_df, col)\n",
    "    hours_df_list.append(temp_hour_df)\n",
    "    \n",
    "    \n",
    "hours_df_openclose = pd.concat(hours_df_list, axis=1)\n",
    "hours_df_openclose.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monday_open        object\n",
       "Monday_close       object\n",
       "Tuesday_open       object\n",
       "Tuesday_close      object\n",
       "Wednesday_open     object\n",
       "Wednesday_close    object\n",
       "Thursday_open      object\n",
       "Thursday_close     object\n",
       "Friday_open        object\n",
       "Friday_close       object\n",
       "Saturday_open      object\n",
       "Saturday_close     object\n",
       "Sunday_open        object\n",
       "Sunday_close       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hours_df_openclose.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key for reference\n",
    "hours_df_openclose['business_id'] = df_bus['business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the work\n",
    "hours_df_openclose.to_csv(path_or_buf='data/cleaned/business_hours.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## is_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quick check for unique values\n",
    "df_bus.is_open.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USA! USA!\n",
    "\n",
    "states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get usa sates and make dataframe\n",
    "df_is_usa = pd.DataFrame(df_bus['state'].str.contains('|'.join(states)).astype(int))\n",
    "df_is_usa['business_id'] = df_bus['business_id']\n",
    "#drop redundant column\n",
    "df_is_usa = df_is_usa.drop(columns=['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the work\n",
    "df_is_usa.to_csv(path_or_buf='data/cleaned/is_usa.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine DFs in master DF with business_id as common key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #superseded in favor for utils.reduce_merge\n",
    "\n",
    "# #combine in massive df\n",
    "# df_list = [df_bus, \n",
    "#            road_type_df_cats, \n",
    "#            df_atr_conc.drop(columns=['business_id']), \n",
    "#            cat_type_df.drop(columns=['business_id']), \n",
    "#            hours_df_openclose.drop(columns=['business_id']), \n",
    "#            df_is_usa.drop(columns=['business_id'])]\n",
    "\n",
    "# df_bus_conc = pd.concat(df_list, axis=1)\n",
    "\n",
    "# df_bus_conc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192609, 120)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine in massive df\n",
    "df_list = [df_bus, \n",
    "           df_atr_conc, \n",
    "           cat_type_df, \n",
    "           hours_df_openclose, \n",
    "           df_is_usa]\n",
    "\n",
    "df_bus_conc = utils.reduce_merge(df_list, key='business_id')\n",
    "\n",
    "df_bus_conc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address,   attributes,   business_id,   categories,   city,   hours,   is_open,   latitude,   longitude,   name,   postal_code,   review_count,   stars,   state,   road_type,   GoodForKids,   RestaurantsReservations,   Caters,   RestaurantsTableService,   RestaurantsTakeOut,   RestaurantsPriceRange2,   OutdoorSeating,   BikeParking,   HasTV,   RestaurantsGoodForGroups,   RestaurantsDelivery,   BusinessAcceptsCreditCards,   BusinessAcceptsBitcoin,   ByAppointmentOnly,   AcceptsInsurance,   GoodForDancing,   CoatCheck,   HappyHour,   WheelchairAccessible,   DogsAllowed,   DriveThru,   Corkage,   BYOB,   Open24Hours,   RestaurantsCounterService,   dessert,   latenight,   lunch,   dinner,   brunch,   breakfast,   garage,   street,   validated,   lot,   valet,   romantic,   intimate,   classy,   hipster,   divey,   touristy,   trendy,   upscale,   casual,   dj,   background_music,   no_music,   jukebox,   live,   video,   karaoke,   monday,   tuesday,   friday,   wednesday,   thursday,   sunday,   saturday,   straightperms,   coloring,   extensions,   africanamerican,   curly,   kids,   perms,   asian,   dairy_free,   gluten_free,   vegan,   kosher,   halal,   soy_free,   vegetarian,   NoiseLevel,   WiFi,   Alcohol,   RestaurantsAttire,   BYOBCorkage,   Smoking,   AgesAllowed,   Restaurants,   Food,   Shopping,   Home,   Spas,   Bars,   Beauty,   Medical,   Health,   Hair,   Monday_open,   Monday_close,   Tuesday_open,   Tuesday_close,   Wednesday_open,   Wednesday_close,   Thursday_open,   Thursday_close,   Friday_open,   Friday_close,   Saturday_open,   Saturday_close,   Sunday_open,   Sunday_close\n"
     ]
    }
   ],
   "source": [
    "#check columns\n",
    "print(*df_bus_conc.columns, sep=',   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the work\n",
    "df_bus_conc.to_csv(path_or_buf='data/cleaned/df_bus_conc.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
